{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d58a8554",
   "metadata": {},
   "source": [
    "# Document Reader using LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca4b60f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in ./opt/anaconda3/lib/python3.9/site-packages (0.10.44)\n",
      "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index) (0.1.6)\n",
      "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index) (0.1.12)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index) (0.9.48)\n",
      "Requirement already satisfied: llama-index-core==0.10.44 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index) (0.10.44)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index) (0.1.3)\n",
      "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index) (0.1.25)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse<0.2.0,>=0.1.2 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index) (0.1.4)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index) (0.1.6)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index) (0.1.6)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index) (0.1.10)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index) (0.2.7)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.13 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index) (0.1.22)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core==0.10.44->llama-index) (10.3.0)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core==0.10.44->llama-index) (3.8.1)\n",
      "Requirement already satisfied: networkx>=3.0 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core==0.10.44->llama-index) (3.2.1)\n",
      "Requirement already satisfied: dataclasses-json in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core==0.10.44->llama-index) (0.6.7)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core==0.10.44->llama-index) (3.9.5)\n",
      "Requirement already satisfied: numpy in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core==0.10.44->llama-index) (1.24.4)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core==0.10.44->llama-index) (0.1.19)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core==0.10.44->llama-index) (1.0.8)\n",
      "Requirement already satisfied: pandas in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core==0.10.44->llama-index) (2.2.2)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core==0.10.44->llama-index) (6.0.1)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core==0.10.44->llama-index) (0.9.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core==0.10.44->llama-index) (8.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core==0.10.44->llama-index) (4.10.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core==0.10.44->llama-index) (0.7.0)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core==0.10.44->llama-index) (2.0.30)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core==0.10.44->llama-index) (4.66.4)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core==0.10.44->llama-index) (2.32.3)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core==0.10.44->llama-index) (1.2.14)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core==0.10.44->llama-index) (1.6.0)\n",
      "Requirement already satisfied: httpx in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core==0.10.44->llama-index) (0.27.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core==0.10.44->llama-index) (2023.10.0)\n",
      "Requirement already satisfied: openai>=1.1.0 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core==0.10.44->llama-index) (1.30.4)\n",
      "Requirement already satisfied: wrapt in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core==0.10.44->llama-index) (1.14.1)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.26)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.2.0)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
      "Requirement already satisfied: llama-parse<0.5.0,>=0.4.0 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index) (0.4.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.44->llama-index) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.44->llama-index) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.44->llama-index) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.44->llama-index) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.44->llama-index) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.44->llama-index) (21.4.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./opt/anaconda3/lib/python3.9/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.3.1)\n",
      "Requirement already satisfied: pydantic>=1.10 in ./opt/anaconda3/lib/python3.9/site-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core==0.10.44->llama-index) (2.7.2)\n",
      "Requirement already satisfied: idna in ./opt/anaconda3/lib/python3.9/site-packages (from httpx->llama-index-core==0.10.44->llama-index) (3.3)\n",
      "Requirement already satisfied: httpcore==1.* in ./opt/anaconda3/lib/python3.9/site-packages (from httpx->llama-index-core==0.10.44->llama-index) (1.0.5)\n",
      "Requirement already satisfied: anyio in ./opt/anaconda3/lib/python3.9/site-packages (from httpx->llama-index-core==0.10.44->llama-index) (3.5.0)\n",
      "Requirement already satisfied: certifi in ./opt/anaconda3/lib/python3.9/site-packages (from httpx->llama-index-core==0.10.44->llama-index) (2024.6.2)\n",
      "Requirement already satisfied: sniffio in ./opt/anaconda3/lib/python3.9/site-packages (from httpx->llama-index-core==0.10.44->llama-index) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./opt/anaconda3/lib/python3.9/site-packages (from httpcore==1.*->httpx->llama-index-core==0.10.44->llama-index) (0.14.0)\n",
      "Requirement already satisfied: joblib in ./opt/anaconda3/lib/python3.9/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.44->llama-index) (1.3.2)\n",
      "Requirement already satisfied: click in ./opt/anaconda3/lib/python3.9/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.44->llama-index) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./opt/anaconda3/lib/python3.9/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.44->llama-index) (2022.7.9)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./opt/anaconda3/lib/python3.9/site-packages (from openai>=1.1.0->llama-index-core==0.10.44->llama-index) (1.9.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./opt/anaconda3/lib/python3.9/site-packages (from requests>=2.31.0->llama-index-core==0.10.44->llama-index) (1.26.18)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./opt/anaconda3/lib/python3.9/site-packages (from requests>=2.31.0->llama-index-core==0.10.44->llama-index) (2.1.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./opt/anaconda3/lib/python3.9/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.44->llama-index) (1.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./opt/anaconda3/lib/python3.9/site-packages (from typing-inspect>=0.8.0->llama-index-core==0.10.44->llama-index) (0.4.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./opt/anaconda3/lib/python3.9/site-packages (from dataclasses-json->llama-index-core==0.10.44->llama-index) (3.21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./opt/anaconda3/lib/python3.9/site-packages (from pandas->llama-index-core==0.10.44->llama-index) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./opt/anaconda3/lib/python3.9/site-packages (from pandas->llama-index-core==0.10.44->llama-index) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./opt/anaconda3/lib/python3.9/site-packages (from pandas->llama-index-core==0.10.44->llama-index) (2024.1)\n",
      "Requirement already satisfied: packaging>=17.0 in ./opt/anaconda3/lib/python3.9/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core==0.10.44->llama-index) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./opt/anaconda3/lib/python3.9/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core==0.10.44->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.3 in ./opt/anaconda3/lib/python3.9/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core==0.10.44->llama-index) (2.18.3)\n",
      "Requirement already satisfied: six>=1.5 in ./opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core==0.10.44->llama-index) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8df7774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-core in ./opt/anaconda3/lib/python3.9/site-packages (0.10.44)\n",
      "Requirement already satisfied: llama-index-readers-file in ./opt/anaconda3/lib/python3.9/site-packages (0.1.25)\n",
      "Requirement already satisfied: llama-index-llms-ollama in ./opt/anaconda3/lib/python3.9/site-packages (0.1.5)\n",
      "Requirement already satisfied: llama-index-embeddings-huggingface in ./opt/anaconda3/lib/python3.9/site-packages (0.2.2)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core) (1.0.8)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core) (8.3.0)\n",
      "Requirement already satisfied: numpy in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core) (1.24.4)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core) (0.7.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core) (6.0.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core) (4.66.4)\n",
      "Requirement already satisfied: networkx>=3.0 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core) (3.2.1)\n",
      "Requirement already satisfied: openai>=1.1.0 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core) (1.30.4)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core) (1.6.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core) (4.10.0)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core) (3.8.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core) (10.3.0)\n",
      "Requirement already satisfied: httpx in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core) (0.27.0)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core) (2.0.30)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core) (2023.10.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core) (0.1.19)\n",
      "Requirement already satisfied: dataclasses-json in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core) (1.2.14)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core) (3.9.5)\n",
      "Requirement already satisfied: wrapt in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core) (1.14.1)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core) (2.32.3)\n",
      "Requirement already satisfied: pandas in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-core) (2.2.2)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-readers-file) (4.2.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-readers-file) (0.0.26)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-readers-file) (4.12.3)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.1 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-embeddings-huggingface) (3.0.1)\n",
      "Requirement already satisfied: huggingface-hub[inference]>=0.19.0 in ./opt/anaconda3/lib/python3.9/site-packages (from llama-index-embeddings-huggingface) (0.21.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.9.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (21.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.3.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./opt/anaconda3/lib/python3.9/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in ./opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (23.2)\n",
      "Requirement already satisfied: filelock in ./opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.13.3)\n",
      "Requirement already satisfied: pydantic<3.0,>1.1 in ./opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.7.2)\n",
      "Requirement already satisfied: httpcore==1.* in ./opt/anaconda3/lib/python3.9/site-packages (from httpx->llama-index-core) (1.0.5)\n",
      "Requirement already satisfied: idna in ./opt/anaconda3/lib/python3.9/site-packages (from httpx->llama-index-core) (3.3)\n",
      "Requirement already satisfied: anyio in ./opt/anaconda3/lib/python3.9/site-packages (from httpx->llama-index-core) (3.5.0)\n",
      "Requirement already satisfied: sniffio in ./opt/anaconda3/lib/python3.9/site-packages (from httpx->llama-index-core) (1.2.0)\n",
      "Requirement already satisfied: certifi in ./opt/anaconda3/lib/python3.9/site-packages (from httpx->llama-index-core) (2024.6.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./opt/anaconda3/lib/python3.9/site-packages (from httpcore==1.*->httpx->llama-index-core) (0.14.0)\n",
      "Requirement already satisfied: joblib in ./opt/anaconda3/lib/python3.9/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core) (1.3.2)\n",
      "Requirement already satisfied: click in ./opt/anaconda3/lib/python3.9/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./opt/anaconda3/lib/python3.9/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core) (2022.7.9)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./opt/anaconda3/lib/python3.9/site-packages (from openai>=1.1.0->llama-index-core) (1.9.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./opt/anaconda3/lib/python3.9/site-packages (from requests>=2.31.0->llama-index-core) (1.26.18)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./opt/anaconda3/lib/python3.9/site-packages (from requests>=2.31.0->llama-index-core) (2.1.1)\n",
      "Requirement already satisfied: scipy in ./opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.9.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.2.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in ./opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (4.38.2)\n",
      "Requirement already satisfied: scikit-learn in ./opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.0.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./opt/anaconda3/lib/python3.9/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core) (1.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./opt/anaconda3/lib/python3.9/site-packages (from typing-inspect>=0.8.0->llama-index-core) (0.4.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./opt/anaconda3/lib/python3.9/site-packages (from dataclasses-json->llama-index-core) (3.21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./opt/anaconda3/lib/python3.9/site-packages (from pandas->llama-index-core) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./opt/anaconda3/lib/python3.9/site-packages (from pandas->llama-index-core) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./opt/anaconda3/lib/python3.9/site-packages (from pandas->llama-index-core) (2022.1)\n",
      "Requirement already satisfied: pydantic-core==2.18.3 in ./opt/anaconda3/lib/python3.9/site-packages (from pydantic<3.0,>1.1->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.18.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./opt/anaconda3/lib/python3.9/site-packages (from pydantic<3.0,>1.1->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in ./opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core) (1.16.0)\n",
      "Requirement already satisfied: jinja2 in ./opt/anaconda3/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.11.3)\n",
      "Requirement already satisfied: sympy in ./opt/anaconda3/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.10.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./opt/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.4.2)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./opt/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.15.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in ./opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./opt/anaconda3/lib/python3.9/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install llama-index-core llama-index-readers-file llama-index-llms-ollama llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09304657",
   "metadata": {},
   "source": [
    "# Loading LLM from Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eed5a7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core import Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4a3cd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"llama3\", request_timeout=120.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441f1d8d",
   "metadata": {},
   "source": [
    "# Prompting an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c402994",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = llm.complete(\"Who is Paul Graham?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4421970f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Graham (1946-2011) was a Northern Irish Anglican priest and theologian who played a significant role in the ecumenical movement, particularly in the area of Christian-Islamic dialogue.\n",
      "\n",
      "Graham was born in Belfast, Northern Ireland. He studied theology at Trinity College, Dublin, and later earned his Ph.D. from the University of Cambridge. He served as a parish priest in various churches in England and Ireland before becoming the Anglican Chaplain to the British Forces in Germany (1974-1980).\n",
      "\n",
      "Graham was deeply interested in interfaith dialogue and worked extensively with Muslim scholars and leaders. In 1982, he founded the Islamic-Anglican Dialogue, which aimed to promote understanding and cooperation between Muslims and Christians. He also played a key role in establishing the British Council of Churches' Commission on Inter-Faith Relations.\n",
      "\n",
      "Throughout his career, Graham traveled widely, engaging in ecumenical and interfaith dialogue with people from diverse religious backgrounds. His work took him to various parts of the world, including the Middle East, North Africa, and Southeast Asia. He was a respected figure in international Christian-Muslim relations and wrote several books on this topic.\n",
      "\n",
      "Paul Graham passed away in 2011, but his legacy continues to inspire interfaith dialogue and cooperation between Christians and Muslims around the world.\n"
     ]
    }
   ],
   "source": [
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17d41c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"You are a pirate with a colorful personality\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"What is your name\"),\n",
    "]\n",
    "resp = llm.chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8768ca36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Arrrr, me hearty! Me name be Captain Blackheart Billy, the most feared and infamous pirate to ever sail the Seven Seas! I be a swashbucklin' scoundrel, with a heart o' gold and a spirit o' steel. Me ship be the \"Maverick's Revenge,\" and me crew be the bravest and most loyal buccaneers on the high seas!\n",
      "\n",
      "Now, what be bringin' ye to these fair waters? Are ye lookin' for adventure, treasure, or maybe just a bit o' pirate lore? Let's hoist the Jolly Roger and set sail fer a tale that'll make yer timbers shiver!\n"
     ]
    }
   ],
   "source": [
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30be5707",
   "metadata": {},
   "source": [
    "# Load a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0b5975c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-07-02 11:43:31--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 75042 (73K) [text/plain]\n",
      "Saving to: 'data/paul_graham/paul_graham_essay.txt'\n",
      "\n",
      "data/paul_graham/pa 100%[===================>]  73.28K  --.-KB/s    in 0.004s  \n",
      "\n",
      "2024-07-02 11:43:31 (18.8 MB/s) - 'data/paul_graham/paul_graham_essay.txt' saved [75042/75042]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p 'data/paul_graham/'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deae7609",
   "metadata": {},
   "source": [
    "# Index and Query document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d47553d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "#llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "documents = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()\n",
    "\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "876d8f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no mention of Joe Biden in the provided context. The text only talks about Paul Graham, his experiences, and his writings. Therefore, I cannot provide an answer to the query as it is not relevant to the given context.\n"
     ]
    }
   ],
   "source": [
    "print(index.as_query_engine(llm=llm).query(\"Who is Joe Biden?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7eb74044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context information, Paul Graham is the author of the essay.\n"
     ]
    }
   ],
   "source": [
    "print(index.as_query_engine(llm=llm).query(\"Who is Paul?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "84be0908",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "text_qa_template_str = (\n",
    "    \"Context information is\"\n",
    "    \" below.\\n---------------------\\n{context_str}\\n---------------------\\nUsing\"\n",
    "    \" both the context information and also using your own knowledge, answer\"\n",
    "    \" the question: {query_str}\\nIf the context isn't helpful, you can also\"\n",
    "    \" answer the question on your own.\\n\"\n",
    ")\n",
    "text_qa_template = PromptTemplate(text_qa_template_str)\n",
    "\n",
    "refine_template_str = (\n",
    "    \"The original question is as follows: {query_str}\\nWe have provided an\"\n",
    "    \" existing answer: {existing_answer}\\nWe have the opportunity to refine\"\n",
    "    \" the existing answer (only if needed) with some more context\"\n",
    "    \" below.\\n------------\\n{context_msg}\\n------------\\nUsing both the new\"\n",
    "    \" context and your own knowledge, update or repeat the existing answer.\\n\"\n",
    ")\n",
    "refine_template = PromptTemplate(refine_template_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d355a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think there may be some confusion here!\n",
      "\n",
      "The text provided is an essay written by Paul Graham, a well-known entrepreneur, investor, and writer. There is no mention of Joe Biden in this essay.\n",
      "\n",
      "So, I won't be able to provide an answer to who Joe Biden is based on the context information you've provided. However, if you're interested, Joe Biden is the 46th Vice President of the United States, serving from 2009 to 2017 under President Barack Obama. He has also been a U.S. Senator from Delaware since 1973 and was a Democratic candidate for the presidential nomination in the 2020 election.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    index.as_query_engine(\n",
    "        text_qa_template=text_qa_template,\n",
    "        refine_template=refine_template,\n",
    "        llm=llm,\n",
    "    ).query(\"Who is Joe Biden?\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a75c9f7",
   "metadata": {},
   "source": [
    "# Storing an index into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "932e4d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "\n",
    "index.storage_context.persist(persist_dir=\"<persist_dir>\")\n",
    "\n",
    "# rebuild storage context\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"<persist_dir>\")\n",
    "\n",
    "# load index\n",
    "index_loaded = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "82ee48a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no mention of Donald Trump in the provided context. The text only discusses Paul Graham's experiences with Y Combinator, startups, Lisp, writing, and angel investing, but does not mention Donald Trump at all.\n"
     ]
    }
   ],
   "source": [
    "print(index.as_query_engine(llm=llm).query(\"Who is Donald Trump?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "69d5a3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no mention of Donald Trump in the provided context. Therefore, I cannot provide an answer that references any specific information about him.\n"
     ]
    }
   ],
   "source": [
    "print(index_loaded.as_query_engine(llm=llm).query(\"Who is Donald Trump?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4b82e069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context information, Paul Graham is an individual who co-founded Y Combinator, a startup accelerator, along with Jessica Livingston. He also co-founded Viaweb, which later became Yahoo!. The essay describes his experiences and ideas about starting angel investments, creating Y Combinator, and developing software for online stores.\n"
     ]
    }
   ],
   "source": [
    "print(index.as_query_engine(llm=llm).query(\"Who is Paul Graham?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "00224413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context information, Paul Graham is the author of the essay described in the text. He is a well-known entrepreneur, investor, and writer who co-founded Y Combinator, an accelerator program that has funded numerous successful startups. In this essay, Graham shares his experiences as an angel investor and founder of various companies, including Viaweb and Y Combinator.\n"
     ]
    }
   ],
   "source": [
    "print(index_loaded.as_query_engine(llm=llm).query(\"Who is Paul Graham?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da166573",
   "metadata": {},
   "source": [
    "# Retrieving and Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2c951997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, get_response_synthesizer\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "\n",
    "# build index\n",
    "# index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "# configure retriever\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "91bc038c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The author, who grew up spending time at the Carnegie Institute, started taking art classes at Harvard while in a PhD program in computer science. His name is Paul Graham.\n"
     ]
    }
   ],
   "source": [
    "# configure response synthesizer\n",
    "response_synthesizer = get_response_synthesizer()\n",
    "\n",
    "# assemble query engine\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    "    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.7)],\n",
    ")\n",
    "\n",
    "# query\n",
    "response = query_engine.query(\"What did the author do growing up and what is his name?\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
